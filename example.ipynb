{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fno import Net2d\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 1, 3, 3])\n",
      "tensor([[[-0.5771, -1.2310, -0.8760],\n",
      "         [-1.6162, -2.5681,  0.1564],\n",
      "         [ 0.9137,  0.8912, -1.5376]]])\n",
      "tensor([[[ 0.8716, -1.4187, -0.7957],\n",
      "         [-0.1223,  0.6164, -0.6945],\n",
      "         [ 1.3738, -0.3663,  1.4960]]])\n",
      "torch.Size([10, 5, 3, 3])\n",
      "tensor([[-0.5771, -1.2310, -0.8760],\n",
      "        [-1.6162, -2.5681,  0.1564],\n",
      "        [ 0.9137,  0.8912, -1.5376]])\n",
      "tensor([[ 0.8716, -1.4187, -0.7957],\n",
      "        [-0.1223,  0.6164, -0.6945],\n",
      "        [ 1.3738, -0.3663,  1.4960]])\n"
     ]
    }
   ],
   "source": [
    "b = a.flatten(start_dim=0, end_dim=1)\n",
    "b = b.unsqueeze(1)\n",
    "b = b.reshape(10, 5, 1, 3, 3)\n",
    "print(b.shape)\n",
    "print(b[0, 0, :, :])\n",
    "print(b[-1, -1, :, :])\n",
    "b = b.flatten(start_dim=1, end_dim=2)\n",
    "print(b.shape)\n",
    "print(b[0, 0, :, :])\n",
    "print(b[-1, -1, :, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5771, -1.2310, -0.8760],\n",
      "        [-1.6162, -2.5681,  0.1564],\n",
      "        [ 0.9137,  0.8912, -1.5376]])\n",
      "tensor([[ 0.8716, -1.4187, -0.7957],\n",
      "        [-0.1223,  0.6164, -0.6945],\n",
      "        [ 1.3738, -0.3663,  1.4960]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(10, 5, 3, 3)\n",
    "print(a[0,0,:,:])\n",
    "print(a[-1,-1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 1, 1])\n",
      "torch.Size([10, 3, 1, 4, 4])\n",
      "tensor([[[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([1.0, 2.0, 3.0]).reshape(3, 1)\n",
    "c = c.unsqueeze(-1)\n",
    "c = c.unsqueeze(-1)\n",
    "c = c.unsqueeze(0)\n",
    "print(c.shape)\n",
    "c = c.repeat(10, 1, 1, 4, 4)\n",
    "print(c.shape)\n",
    "print(c[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "wavelen = [0.443, 0.490, 0.560, 0.665, 0.705, 0.740, 0.783, 0.842, 0.865, 0.945, 1.610, 2.190]\n",
    "wavelen = torch.tensor(wavelen).reshape(12, 1).unsqueeze(-1).unsqueeze(-1).unsqueeze(0)\n",
    "print(wavelen.shape)\n",
    "wave = wavelen.repeat(32, 1, 1, 120, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 1, 120, 120])\n",
      "tensor([[[0.6650, 0.6650, 0.6650,  ..., 0.6650, 0.6650, 0.6650],\n",
      "         [0.6650, 0.6650, 0.6650,  ..., 0.6650, 0.6650, 0.6650],\n",
      "         [0.6650, 0.6650, 0.6650,  ..., 0.6650, 0.6650, 0.6650],\n",
      "         ...,\n",
      "         [0.6650, 0.6650, 0.6650,  ..., 0.6650, 0.6650, 0.6650],\n",
      "         [0.6650, 0.6650, 0.6650,  ..., 0.6650, 0.6650, 0.6650],\n",
      "         [0.6650, 0.6650, 0.6650,  ..., 0.6650, 0.6650, 0.6650]]])\n"
     ]
    }
   ],
   "source": [
    "print(wave.shape)\n",
    "print(wave[2, 3, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = torch.ones(32, 1, 120, 120)\n",
    "for i in range(11):\n",
    "    x = torch.ones(32, 1, 120, 120) * (i+2)\n",
    "    x_all = torch.cat((x_all, x), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 1, 120, 120])\n"
     ]
    }
   ],
   "source": [
    "x_all = x_all.unsqueeze(2)\n",
    "print(x_all.shape)\n",
    "newx = torch.cat((x_all, wave), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 2, 120, 120])\n",
      "tensor([[ 1.0000,  0.4430],\n",
      "        [ 2.0000,  0.4900],\n",
      "        [ 3.0000,  0.5600],\n",
      "        [ 4.0000,  0.6650],\n",
      "        [ 5.0000,  0.7050],\n",
      "        [ 6.0000,  0.7400],\n",
      "        [ 7.0000,  0.7830],\n",
      "        [ 8.0000,  0.8420],\n",
      "        [ 9.0000,  0.8650],\n",
      "        [10.0000,  0.9450],\n",
      "        [11.0000,  1.6100],\n",
      "        [12.0000,  2.1900]])\n"
     ]
    }
   ],
   "source": [
    "print(newx.shape)\n",
    "print(newx[1, :, :, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fno import Net2d\n",
    "from resnet import resnet20\n",
    "class ConvWeightGen(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, in_dim, hidden_dim):\n",
    "        # input: condition used to generate the weights (shape: indim)\n",
    "        # output: weights for convolutional layer (shape: out_channels, in_channels, kernel_size, kernel_size)\n",
    "        super(ConvWeightGen, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.indim = in_dim\n",
    "        self.layers = []\n",
    "        for i in range(in_channels):\n",
    "            self.layer.append(nn.Linear(in_dim, hidden_dim))\n",
    "        self.linear = nn.Linear(hidden_dim, out_channels * kernel_size * kernel_size)\n",
    "    def forward(self, x):\n",
    "        # x: condition used to generate the weights (shape: indim)\n",
    "        # return: weights for convolutional layer (shape: out_channels, in_channels, kernel_size, kernel_size)\n",
    "        xlist = []\n",
    "        x_copy = x.copy()\n",
    "        for i in range(self.in_channels):\n",
    "            intermd = self.layers[i](x_copy)\n",
    "            intermd = self.linear(intermd) # shape: out_channels * kernel_size * kernel_size\n",
    "            intermd = intermd.reshape(self.out_channels, self.kernel_size, self.kernel_size)\n",
    "            xlist.append(intermd)\n",
    "        return torch.stack(xlist, dim=1)\n",
    "    \n",
    "class WaveModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, in_dim, hidden_dim, batch_size, num_band):\n",
    "        super(WaveModule, self).__init__()\n",
    "        # in_channels = 1\n",
    "        # out_channels = 16\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv_weight_gen = ConvWeightGen(in_channels, out_channels, kernel_size, in_dim, hidden_dim)\n",
    "        self.conv_static = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.conv_dynamic = nn.Conv2d(in_channels*batch_size*num_band, out_channels*batch_size*num_band, kernel_size, stride, padding, groups=batch_size*num_band)\n",
    "\n",
    "    def forward(self, x, wave):\n",
    "        # x: (batch_size, num_band*in_channel, h, w)\n",
    "        # wave: (num_band, 1)\n",
    "        b, _, h, w = x.shape\n",
    "        c = wave.shape[0]\n",
    "        wave = wave.repeat(b, 1) # shape: batch_size*num_band, 1\n",
    "        x = x.reshape(b, c, self.in_channels, h, w) # shape: batch_size, num_band, in_channels, h, w\n",
    "        x = x.flatten(start_dim=0, end_dim=1) # shape: batch_size*num_band, in_channels, h, w\n",
    "        gen_weight = self.conv_weight_gen(wave) # shape: batch_size*num_band, out_channels, in_channels, kernel_size, kernel_size\n",
    "        self.conv_dynamic.weight = gen_weight.flatten(start_dim=0, end_dim=1) # shape: batch_size*num_band*out_channels, in_channels, kernel_size, kernel_size\n",
    "        static_output = self.conv_static(x).reshape(b, c, self.out_channels, h, w).flatten(start_dim=1, end_dim=2) # shape: batch_size, num_band*out_channels, h, w\n",
    "        dynamic_output = self.conv_dynamic(x.flatten(start_dim=0, end_dim=1).unsqueeze(0)).squeeze(0).reshape(b, c*self.out_channels, h, w)\n",
    "        return static_output + dynamic_output\n",
    "    \n",
    "class DynEmbedder(nn.Module):\n",
    "    def __init__(self, mid_channels, out_channels, kernel_size, stride, padding, in_dim, hidden_dim, batch_size, num_band):\n",
    "        super(DynEmbedder, self).__init__()\n",
    "        self.wave_module1 = WaveModule(1, mid_channels, kernel_size, stride, padding, in_dim, hidden_dim, batch_size, num_band)\n",
    "        self.wave_module2 = WaveModule(mid_channels, out_channels, kernel_size, stride, padding, in_dim, hidden_dim, batch_size, num_band)\n",
    "        self.embedder = resnet20(in_channel = num_band*mid_channels, num_classes = num_band*mid_channels, remain_shape = True)\n",
    "    def forward(self, x, wave):\n",
    "        # x: (batch_size, num_band*in_channel, h, w)\n",
    "        # wave: (num_band, 1)\n",
    "        x = self.wave_module1(x, wave)\n",
    "        x = self.embedder(x)\n",
    "        x = self.wave_module2(x, wave)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3, 3])\n",
      "torch.Size([1, 4, 5, 5])\n",
      "tensor([0., 0., 9., 9.], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "conv = nn.Conv2d(2, 4, 3, 1, 1, groups=2)\n",
    "print(conv.weight.shape)\n",
    "conv.weight = nn.Parameter(torch.cat((torch.zeros(2, 1, 3, 3), torch.ones(2, 1, 3, 3)), dim=0))\n",
    "conv.bias = nn.Parameter(torch.zeros(4))\n",
    "x = torch.ones(1, 2, 5, 5)\n",
    "y = conv(x)\n",
    "print(y.shape)\n",
    "print(y[0,:,1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.cat((torch.ones(1,3,3), torch.ones(1,3,3)*2, torch.ones(1,3,3)*3), dim=0)\n",
    "x = x.flatten(start_dim=0, end_dim=1)\n",
    "x = x.reshape(3,3,3)\n",
    "print(x[:3,0,0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
